fastapi==0.111.0
uvicorn[standard]==0.30.1
transformers==4.41.2
exllamav2==0.3.2
torch --index-url https://download.pytorch.org/whl/cu129
torchvision --index-url https://download.pytorch.org/whl/cu129
llama-cpp-python
