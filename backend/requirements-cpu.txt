fastapi==0.111.0
uvicorn[standard]==0.30.1
transformers==4.41.2
torch==2.7.1 # CPU-only PyTorch
llama-cpp-python
